{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9dac3258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rltk\n",
    "import csv\n",
    "from datetime import datetime\n",
    "tokenizer = rltk.tokenizer.crf_tokenizer.crf_tokenizer.CrfTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16fc8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processskill(string):\n",
    "    skills = string.split(\";\")\n",
    "    newskills = []\n",
    "    for skill in skills:\n",
    "        newskill = skill.lower()\n",
    "        newskill = newskill.replace(\"[^a-zA-Z]+\", \"\")\n",
    "        newskills.append(newskill)\n",
    "    return \";\".join(newskills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62ed5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class glassdoorRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    # attribute 1: job title\n",
    "    @rltk.cached_property\n",
    "    def title_string(self):\n",
    "        return self.raw_object['job_title']\n",
    "    \n",
    "    # attribute 2: company name\n",
    "    @rltk.cached_property\n",
    "    def company_string(self):\n",
    "        return self.raw_object['company_name']\n",
    "    \n",
    "    # attribute 3: location (city)\n",
    "    @rltk.cached_property\n",
    "    def city_string(self):\n",
    "        return self.raw_object['city']\n",
    "    \n",
    "    # attribute 4: location(state)\n",
    "    @rltk.cached_property\n",
    "    def state_string(self):\n",
    "        return self.raw_object['state/area']\n",
    "    \n",
    "    # attribute 5: job_details\n",
    "    @rltk.cached_property\n",
    "    def desc_string(self):\n",
    "        return self.raw_object['job_details']\n",
    "    \n",
    "    # attribute 6: salary\n",
    "    @rltk.cached_property\n",
    "    def salary_string(self):\n",
    "        return self.raw_object['salary']\n",
    "    \n",
    "    # attribute 7: url\n",
    "    @rltk.cached_property\n",
    "    def url_string(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    # attribute 8: diploma\n",
    "    @rltk.cached_property\n",
    "    def diploma_string(self):\n",
    "        return self.raw_object['DIPLOMA']\n",
    "    \n",
    "    # attribute 9: skills\n",
    "    @rltk.cached_property\n",
    "    def skill_list(self):\n",
    "        skills = self.raw_object['SKILLS']\n",
    "        return processskill(skills)\n",
    "    \n",
    "    # attribute 10: diploma major\n",
    "    @rltk.cached_property\n",
    "    def diploma_major_string(self):\n",
    "        return self.raw_object['DIPLOMA_MAJOR']\n",
    "    \n",
    "    # attribute 11: experience\n",
    "    @rltk.cached_property\n",
    "    def experience_string(self):\n",
    "        return self.raw_object['EXPERIENCE']\n",
    "    \n",
    "    # attribute 12: source\n",
    "    @rltk.cached_property\n",
    "    def source_string(self):\n",
    "        return self.raw_object['source']\n",
    "    \n",
    "    # attribute 13: work type\n",
    "    @rltk.cached_property\n",
    "    def worktype_string(self):\n",
    "        return self.raw_object['work_type']\n",
    "    \n",
    "    # attribute 14: category\n",
    "    @rltk.cached_property\n",
    "    def category_string(self):\n",
    "        return self.raw_object['job_category']\n",
    "    \n",
    "    # attribute 15: location\n",
    "    @rltk.cached_property\n",
    "    def location_string(self):\n",
    "        return self.raw_object['location']\n",
    "    \n",
    "class linkedinRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    # attribute 1: job title\n",
    "    @rltk.cached_property\n",
    "    def title_string(self):\n",
    "        return self.raw_object['job_title']\n",
    "    \n",
    "    # attribute 2: company name\n",
    "    @rltk.cached_property\n",
    "    def company_string(self):\n",
    "        return self.raw_object['company_name']\n",
    "    \n",
    "    # attribute 3: location (city)\n",
    "    @rltk.cached_property\n",
    "    def city_string(self):\n",
    "        return self.raw_object['city']\n",
    "    \n",
    "    # attribute 4: location(state)\n",
    "    @rltk.cached_property\n",
    "    def state_string(self):\n",
    "        return self.raw_object['state/area']\n",
    "    \n",
    "    # attribute 5: job_details\n",
    "    @rltk.cached_property\n",
    "    def desc_string(self):\n",
    "        return self.raw_object['job_details']\n",
    "    \n",
    "    # attribute 6: salary\n",
    "    @rltk.cached_property\n",
    "    def salary_string(self):\n",
    "        return self.raw_object['salary']\n",
    "    \n",
    "    # attribute 7: url\n",
    "    @rltk.cached_property\n",
    "    def url_string(self):\n",
    "        return self.raw_object['url']\n",
    "    \n",
    "    # attribute 8: diploma\n",
    "    @rltk.cached_property\n",
    "    def diploma_string(self):\n",
    "        return self.raw_object['DIPLOMA']\n",
    "    \n",
    "    # attribute 9: skills\n",
    "    @rltk.cached_property\n",
    "    def skill_list(self):\n",
    "        skills = self.raw_object['SKILLS']\n",
    "        return processskill(skills)\n",
    "    \n",
    "    # attribute 10: diploma major\n",
    "    @rltk.cached_property\n",
    "    def diploma_major_string(self):\n",
    "        return self.raw_object['DIPLOMA_MAJOR']\n",
    "    \n",
    "    # attribute 11: experience\n",
    "    @rltk.cached_property\n",
    "    def experience_string(self):\n",
    "        return self.raw_object['EXPERIENCE']\n",
    "    \n",
    "    # attribute 12: source\n",
    "    @rltk.cached_property\n",
    "    def source_string(self):\n",
    "        return self.raw_object['source']\n",
    "    \n",
    "    # attribute 13: work type\n",
    "    @rltk.cached_property\n",
    "    def worktype_string(self):\n",
    "        return self.raw_object['work_type']\n",
    "    \n",
    "    # attribute 14: category\n",
    "    @rltk.cached_property\n",
    "    def category_string(self):\n",
    "        return self.raw_object['job_category']\n",
    "    \n",
    "    # attribute 15: location\n",
    "    @rltk.cached_property\n",
    "    def location_string(self):\n",
    "        return self.raw_object['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ef32fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gCompanyRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    # attribute 1: company name\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['name']\n",
    "    \n",
    "    # attribute 2: headquarter(city)\n",
    "    @rltk.cached_property\n",
    "    def city_string(self):\n",
    "        return self.raw_object['city']\n",
    "    \n",
    "    # attribute 2: headquarter(state)\n",
    "    @rltk.cached_property\n",
    "    def state_string(self):\n",
    "        return self.raw_object['state/area']\n",
    "    \n",
    "    # attribute 3: company size\n",
    "    @rltk.cached_property\n",
    "    def size_string(self):\n",
    "        return self.raw_object['size']\n",
    "    \n",
    "    # attribute 4：website\n",
    "    @rltk.cached_property\n",
    "    def website_string(self):\n",
    "        website = self.raw_object['company_url']\n",
    "        if website != \"\":\n",
    "            if website[-1] != \"/\":\n",
    "                website += \"/\" \n",
    "        return website\n",
    "    \n",
    "    # attribute 5：industry\n",
    "    @rltk.cached_property\n",
    "    def industry_string(self):\n",
    "        return self.raw_object['industry']\n",
    "    \n",
    "    # attribute 6：desc\n",
    "    @rltk.cached_property\n",
    "    def desc_string(self):\n",
    "        return self.raw_object['description']\n",
    "    \n",
    "    # attribute 7：revenue\n",
    "    @rltk.cached_property\n",
    "    def revenue_string(self):\n",
    "        return self.raw_object['revenue']\n",
    "    \n",
    "    # attribute 8：company_type\n",
    "    @rltk.cached_property\n",
    "    def type_string(self):\n",
    "        return self.raw_object['company_type']\n",
    "    \n",
    "    # attribute 9：founded year\n",
    "    @rltk.cached_property\n",
    "    def founded_string(self):\n",
    "        return self.raw_object['founded']\n",
    "    \n",
    "    # attribute 10：img url\n",
    "    @rltk.cached_property\n",
    "    def img_string(self):\n",
    "        return self.raw_object['company_logo']\n",
    "    \n",
    "    # attribute 11: location\n",
    "    @rltk.cached_property\n",
    "    def location_string(self):\n",
    "        return self.raw_object['headquarter']\n",
    "    \n",
    "class lCompanyRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['ID']\n",
    "    \n",
    "    # attribute 1: company name\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['company_name']\n",
    "    \n",
    "    # attribute 2: headquarter(city)\n",
    "    @rltk.cached_property\n",
    "    def city_string(self):\n",
    "        return self.raw_object['city']\n",
    "    \n",
    "    # attribute 2: headquarter(state)\n",
    "    @rltk.cached_property\n",
    "    def state_string(self):\n",
    "        return self.raw_object['state/area']\n",
    "    \n",
    "    # attribute 3: company size\n",
    "    @rltk.cached_property\n",
    "    def size_string(self):\n",
    "        return self.raw_object['size']\n",
    "    \n",
    "    # attribute 4：website\n",
    "    @rltk.cached_property\n",
    "    def website_string(self):\n",
    "        website = self.raw_object['website']\n",
    "        if website != \"\":\n",
    "            if website[-1] != \"/\":\n",
    "                website += \"/\" \n",
    "        return website\n",
    "    \n",
    "    # attribute 5：industry\n",
    "    @rltk.cached_property\n",
    "    def industry_string(self):\n",
    "        return self.raw_object['industry']\n",
    "    \n",
    "    # attribute 6：desc\n",
    "    @rltk.cached_property\n",
    "    def desc_string(self):\n",
    "        return self.raw_object['description']\n",
    "    \n",
    "    # attribute 7：founded year\n",
    "    @rltk.cached_property\n",
    "    def founded_string(self):\n",
    "        return self.raw_object['founded']\n",
    "    \n",
    "    # attribute 8：img url\n",
    "    @rltk.cached_property\n",
    "    def img_string(self):\n",
    "        return self.raw_object['img_url']\n",
    "    \n",
    "    # attribute 9: location\n",
    "    @rltk.cached_property\n",
    "    def location_string(self):\n",
    "        return self.raw_object['headquarters']\n",
    "    \n",
    "\n",
    "class wCompanyRecord(rltk.Record):\n",
    "    def __init__(self, raw_object):\n",
    "        super().__init__(raw_object)\n",
    "        self.name = ''\n",
    "\n",
    "    @rltk.cached_property\n",
    "    def id(self):\n",
    "        return self.raw_object['item']\n",
    "    # attribute 1: company name\n",
    "    @rltk.cached_property\n",
    "    def name_string(self):\n",
    "        return self.raw_object['itemLabel']\n",
    "    \n",
    "    # attribute 2: headquarter\n",
    "    @rltk.cached_property\n",
    "    def headquarter_string(self):\n",
    "        return self.raw_object['locationLabel']\n",
    "    \n",
    "    # attribute 4：website\n",
    "    @rltk.cached_property\n",
    "    def website_string(self):\n",
    "        website = self.raw_object['website']\n",
    "        if website != \"\":\n",
    "            if website[-1] != \"/\":\n",
    "                website += \"/\" \n",
    "        return website\n",
    "    \n",
    "    # attribute 5：founded year\n",
    "    @rltk.cached_property\n",
    "    def founded_string(self):\n",
    "        return self.raw_object['founded'].split(\"-\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4516fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = '../csvfile_category/'\n",
    "glassdoor_file = dir_ + 'glassdoor_req.csv'\n",
    "linkedin_file = dir_ + 'linkedin_req.csv'\n",
    "\n",
    "ds_glassdoor = rltk.Dataset(rltk.CSVReader(glassdoor_file),record_class=glassdoorRecord)\n",
    "ds_linkedin = rltk.Dataset(rltk.CSVReader(linkedin_file),record_class=linkedinRecord)\n",
    "\n",
    "gc_file = dir_ + 'glassdoor_company_withid.csv'\n",
    "lc_file = dir_ + 'linkedin_company_withid.csv'\n",
    "wc_file = dir_ + 'wikidata_company.csv'\n",
    "\n",
    "ds_linkedin_c = rltk.Dataset(rltk.CSVReader(lc_file),record_class=lCompanyRecord)\n",
    "ds_glassdoor_c = rltk.Dataset(rltk.CSVReader(gc_file),record_class=gCompanyRecord)\n",
    "ds_wikidata_c = rltk.Dataset(rltk.CSVReader(wc_file),record_class=wCompanyRecord)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e77c4",
   "metadata": {},
   "source": [
    "### read matched pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4eff44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link = []\n",
    "with open(dir_+'linkage/job_linkage.csv', encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            job_link.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "966e3225",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_link = []\n",
    "with open(dir_+'linkage/g_l_linkage.csv', encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            gl_link.append(row)\n",
    "\n",
    "wl_link = []\n",
    "with open(dir_+'linkage/w_l_linkage.csv', encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            wl_link.append(row)\n",
    "\n",
    "\n",
    "wg_link = []\n",
    "with open(dir_+'linkage/w_g_linkage.csv', encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            wg_link.append(row)\n",
    "\n",
    "glw_link = []\n",
    "with open(dir_+'linkage/g_l_w_linkage.csv', encoding='utf-8', errors=\"replace\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if len(row) <= 1:\n",
    "            continue\n",
    "        if line_count == 0:\n",
    "            columns = row\n",
    "            line_count += 1\n",
    "        else:\n",
    "            glw_link.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2d4a3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gl_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9cc28b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 The Home Depot 2434 The Home Depot\n",
      "6 USAA 2633 USAA\n",
      "18 BP 1168 bp\n",
      "592 Citi 1756 Citi\n",
      "739 CapstoneONE Search 1944 CapstoneONE Search\n",
      "765 Expedition Technology Inc 2229 Expedition Technology Inc\n",
      "25 Liberty Mutual Insurance 2314 Liberty Mutual Insurance\n",
      "29 Ursus, Inc. 1926 Ursus, Inc.\n",
      "30 Harnham 69 Harnham\n",
      "31 Apex Systems 2501 Apex Systems\n",
      "35 Matlen Silver 2086 Matlen Silver\n",
      "143 confidential 2134 Confidential\n",
      "117 Confidential 2134 Confidential\n",
      "52 Analog Devices 1858 Analog Devices\n",
      "324 Paciolan 703 Paciolan\n",
      "60 Peraton 2388 Peraton\n",
      "146 DISYS 1769 DISYS\n",
      "90 Air Products 2396 Air Products\n",
      "95 CyberCoders 1107 CyberCoders\n",
      "102 Navy Federal Credit Union 1673 Navy Federal Credit Union\n",
      "921 DICK'S Sporting Goods 1022 DICK'S Sporting Goods\n",
      "392 SpaceX 1560 SpaceX\n",
      "152 Boutique Recruiting 179 Boutique Recruiting\n",
      "155 GPac 2182 gpac\n",
      "160 CBRE 2427 CBRE\n",
      "198 US Foods 2343 US Foods\n",
      "175 CPS Energy 1696 CPS Energy\n",
      "936 Act! LLC 2680 Act! LLC\n",
      "202 Halff Associates 1235 Halff Associates\n",
      "203 IFG Companies 1352 IFG Companies\n",
      "901 American Red Cross 1065 American Red Cross\n",
      "218 Larson Maddox 373 Larson Maddox\n",
      "221 Cepheid 384 Cepheid\n",
      "270 Aquent 1432 Aquent\n",
      "310 Onward Search 705 Onward Search\n",
      "330 AECOM 1126 AECOM\n",
      "341 RTI International 2271 RTI International\n",
      "360 Gridiron IT 1656 Gridiron IT\n",
      "363 Digital People 775 Digital People\n",
      "377 Kelly 1576 Kelly\n",
      "404 Mainz Brady Group 2651 Mainz Brady Group\n",
      "541 FIS 1438 FIS\n",
      "487 CDM Smith 1237 CDM Smith\n",
      "767 Draper 1801 Draper\n",
      "506 Inceed 278 Inceed\n",
      "513 RETTEW 1215 RETTEW\n",
      "550 Dropbox 1340 Dropbox\n",
      "556 Revel IT 1461 Revel IT\n",
      "567 Grant Street Group 1270 Grant Street Group\n",
      "630 Mastech Digital 2239 Mastech Digital\n",
      "606 Selby Jennings 81 Selby Jennings\n",
      "608 Peterson Technology Partners 2250 Peterson Technology Partners\n",
      "611 MODIS 2496 Modis\n",
      "636 Virtusa 1572 Virtusa\n",
      "651 BairesDev 1075 BairesDev\n",
      "669 IBM 1923 IBM\n",
      "674 Gleeds 1705 Gleeds\n",
      "732 BOEING 2261 Boeing\n",
      "721 Yoh, A Day & Zimmermann Company 1528 Yoh, A Day & Zimmermann Company\n",
      "736 Motorola Solutions 2472 Motorola Solutions\n",
      "779 Uber 2358 Uber\n",
      "780 Deloitte 2386 Deloitte\n",
      "878 Xcel Energy 2011 Xcel Energy\n",
      "888 ektello 1585 ektello\n"
     ]
    }
   ],
   "source": [
    "for id1, id2 in gl_link:\n",
    "    rg = ds_glassdoor_c.get_record(id1)\n",
    "    rl = ds_linkedin_c.get_record(id2)\n",
    "    print(id1, rg.name_string, id2, rl.name_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca8df4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdflib import Graph, URIRef, Literal, XSD, Namespace, RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23f9d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkexist(str2, list1):\n",
    "    exist = False\n",
    "    for str1 in list1:\n",
    "        if rltk.jaro_winkler_similarity(str1, str2) > 0.85:\n",
    "            exist = True\n",
    "    return exist\n",
    "\n",
    "def combine_list(str1, str2):\n",
    "    list1 = str1.split(\";\")\n",
    "    list2 = str2.split(\";\")\n",
    "    newlist = list1\n",
    "    for skill in list2:\n",
    "        if not checkexist(skill, list1):\n",
    "            newlist.append(skill)\n",
    "    return \";\".join(newlist)\n",
    "\n",
    "def combine_str(str1, str2):\n",
    "    if str1 != \"\":\n",
    "        return str1\n",
    "    else:\n",
    "        return str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e8c10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_job(r1, r2):\n",
    "    info = {}\n",
    "    info[\"job_title\"] = r1.title_string\n",
    "    info['job_description'] = r1.desc_string\n",
    "    info['salary'] = r1.salary_string\n",
    "    info['work_type'] = r2.worktype_string\n",
    "    info['url'] = r1.url_string\n",
    "    info['skills'] = combine_list(r1.skill_list, r2.skill_list)\n",
    "    info['diploma'] = combine_str(r1.diploma_string, r2.diploma_string)\n",
    "    info['major'] = combine_str(r1.diploma_major_string, r2.diploma_major_string)\n",
    "    info['experience'] = combine_str(r1.experience_string, r2.experience_string)\n",
    "    info['source'] = r1.source_string\n",
    "    info['company'] = r1.company_string\n",
    "    info['city'] = r2.city_string\n",
    "    info['state'] = r2.state_string\n",
    "    info['category'] = r2.category_string\n",
    "    info['location'] = r2.location_string\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92839d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info = []\n",
    "link_l = [i[1] for i in job_link]\n",
    "for job in ds_linkedin:\n",
    "    if job.id not in link_l:\n",
    "        info = {}\n",
    "        info[\"job_title\"] = job.title_string\n",
    "        info['job_description'] = job.desc_string\n",
    "        info['salary'] = job.salary_string\n",
    "        info['work_type'] = job.worktype_string\n",
    "        info['url'] = job.url_string\n",
    "        info['skills'] = job.skill_list\n",
    "        info['diploma'] = job.diploma_string\n",
    "        info['major'] = job.diploma_major_string\n",
    "        info['experience'] = job.experience_string\n",
    "        info['source'] = job.source_string\n",
    "        info['company'] = job.company_string\n",
    "        info['city'] = job.city_string\n",
    "        info['state'] = job.state_string\n",
    "        info['category'] = job.category_string\n",
    "        info['location'] = job.location_string\n",
    "        job_info.append(info)\n",
    "link_g = [i[0] for i in job_link]\n",
    "for job in ds_glassdoor:\n",
    "    if job.id not in link_g:\n",
    "        info = {}\n",
    "        info[\"job_title\"] = job.title_string\n",
    "        info['job_description'] = job.desc_string\n",
    "        info['salary'] = job.salary_string\n",
    "        info['work_type'] = job.worktype_string\n",
    "        info['url'] = job.url_string\n",
    "        info['skills'] = job.skill_list\n",
    "        info['diploma'] = job.diploma_string\n",
    "        info['major'] = job.diploma_major_string\n",
    "        info['experience'] = job.experience_string\n",
    "        info['source'] = job.source_string\n",
    "        info['company'] = job.company_string\n",
    "        info['city'] = job.city_string\n",
    "        info['state'] = job.state_string\n",
    "        info['category'] = job.category_string\n",
    "        info['location'] = job.location_string\n",
    "        job_info.append(info)\n",
    "\n",
    "for id1, id2 in job_link:\n",
    "    rg = ds_glassdoor.get_record(id1)\n",
    "    rl = ds_linkedin.get_record(id2)\n",
    "    info = combine_job(rg, rl)\n",
    "    job_info.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d7e0ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6631"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ddf3b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_founded(str1, str2): # r1: glassdoor, r2: linkedin\n",
    "    if str1 == \"\":\n",
    "        return str2\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "454d6852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add as glassdoor-linkedin\n"
     ]
    }
   ],
   "source": [
    "company_info = []\n",
    "\n",
    "link_l_c3 = [i[1] for i in glw_link] # three linkage\n",
    "link_l_c2 = [i[1] for i in wl_link if i[1] not in link_l_c3] # wikidata - linkedin \n",
    "link_l_c = [i[1] for i in gl_link if i[1] not in link_l_c3 and i[1] not in link_l_c2] # glassdoor - linkedin \n",
    "\n",
    "# only linkedin\n",
    "for company in ds_linkedin_c:\n",
    "    if company.id not in link_l_c and company.id not in link_l_c2 and company.id not in link_l_c3:\n",
    "        info = {}\n",
    "        info[\"company_name\"] = company.name_string\n",
    "        info['city'] = company.city_string\n",
    "        info['state'] = company.state_string\n",
    "        info['size'] = company.size_string\n",
    "        info['website'] = company.website_string\n",
    "        info['industry'] = company.industry_string\n",
    "        info['description'] = company.desc_string\n",
    "        info['founded'] = company.founded_string\n",
    "        info['logo_url'] = company.img_string\n",
    "        info['location'] = company.location_string\n",
    "        company_info.append(info)\n",
    "\n",
    "# only glassdoor\n",
    "link_g_c3 = [i[0] for i in glw_link] # three linkage\n",
    "link_g_c2 = [i[1] for i in wg_link if i[1] not in link_g_c3] # wikidata - glassdoor \n",
    "link_g_c = [i[0] for i in gl_link if i[0] not in link_g_c3 and i[0] not in link_g_c2] # glassdoor - linkedin \n",
    "\n",
    "for company in ds_glassdoor_c:\n",
    "    if company.id not in link_g_c and company.id not in link_g_c2 and company.id not in link_g_c3:\n",
    "        info = {}\n",
    "        info[\"company_name\"] = company.name_string\n",
    "        info['city'] = company.city_string\n",
    "        info['state'] = company.state_string\n",
    "        info['size'] = company.size_string\n",
    "        info['website'] = company.website_string\n",
    "        info['industry'] = company.industry_string\n",
    "        info['description'] = company.desc_string\n",
    "        info['revenue'] = company.revenue_string\n",
    "        info['founded'] = company.founded_string\n",
    "        info['company_type'] = company.type_string\n",
    "        info['logo_url'] = company.img_string\n",
    "        info['location'] = company.location_string\n",
    "        company_info.append(info)\n",
    "\n",
    "# glassdoor - linkedin\n",
    "for id1, id2 in gl_link:\n",
    "    if id1 not in link_g_c3 and id1 not in link_g_c2:\n",
    "        rg = ds_glassdoor_c.get_record(id1)\n",
    "        rl = ds_linkedin_c.get_record(id2)\n",
    "        if rg.name_string == \"Ursus, Inc.\":\n",
    "            print(\"add as glassdoor-linkedin\")\n",
    "        info = {}\n",
    "        info[\"company_name\"] = rg.name_string\n",
    "        info['city'] = rg.city_string\n",
    "        info['state'] = rg.state_string\n",
    "        info['size'] = rl.size_string\n",
    "        info['website'] = rg.website_string\n",
    "        info['industry'] = rg.industry_string\n",
    "        info['description'] = rg.desc_string\n",
    "        info['revenue'] = rg.revenue_string\n",
    "        info['founded'] = rg.founded_string\n",
    "        info['company_type'] = rg.type_string\n",
    "        info['logo_url'] = rl.img_string\n",
    "        info['location'] = rg.location_string\n",
    "        company_info.append(info)\n",
    "\n",
    "# glassdoor - wikidata\n",
    "for id1, id2 in wg_link:\n",
    "    if id2 not in link_g_c3 and id2 not in link_g_c:\n",
    "        rg = ds_glassdoor_c.get_record(id2)\n",
    "        rw = ds_wikidata_c.get_record(id1)\n",
    "        info = {}\n",
    "        info[\"company_name\"] = rg.name_string\n",
    "        info['city'] = rg.city_string\n",
    "        info['state'] = rg.state_string\n",
    "        info['size'] = rg.size_string\n",
    "        info['website'] = rg.website_string\n",
    "        info['industry'] = rg.industry_string\n",
    "        info['description'] = rg.desc_string\n",
    "        info['revenue'] = rg.revenue_string\n",
    "        info['founded'] = combine_founded(rw.founded_string, rg.founded_string)\n",
    "        info['company_type'] = rg.type_string\n",
    "        info['logo_url'] = rg.img_string\n",
    "        info['location'] = rg.location_string\n",
    "        company_info.append(info)\n",
    "        \n",
    "# linkedin - wikidata\n",
    "for id1, id2 in wl_link:\n",
    "    if id2 not in link_l_c3 and id2 not in link_l_c:\n",
    "        rl = ds_linkedin_c.get_record(id2)\n",
    "        rw = ds_wikidata_c.get_record(id1)\n",
    "        info = {}\n",
    "        info[\"company_name\"] = rl.name_string\n",
    "        info['city'] = rl.city_string\n",
    "        info['state'] = rl.state_string\n",
    "        info['size'] = rl.size_string\n",
    "        info['website'] = rl.website_string\n",
    "        info['industry'] = rl.industry_string\n",
    "        info['description'] = rl.desc_string\n",
    "        info['founded'] = rw.founded_string\n",
    "        info['logo_url'] = rl.img_string\n",
    "        info['location'] = rl.location_string\n",
    "        company_info.append(info)\n",
    "\n",
    "# glassdoor - wikidata - linkedin\n",
    "for id1, id2, id3 in glw_link:\n",
    "    rg = ds_glassdoor_c.get_record(id1)\n",
    "    rw = ds_wikidata_c.get_record(id3)\n",
    "    rl = ds_linkedin_c.get_record(id2)\n",
    "    \n",
    "    info = {}\n",
    "    info[\"company_name\"] = rg.name_string\n",
    "    info['city'] = rg.city_string\n",
    "    info['state'] = rg.state_string\n",
    "    info['size'] = rl.size_string\n",
    "    info['website'] = rg.website_string\n",
    "    info['industry'] = rg.industry_string\n",
    "    info['description'] = rg.desc_string\n",
    "    info['revenue'] = rg.revenue_string\n",
    "    info['founded'] = combine_founded(rw.founded_string, rg.founded_string)\n",
    "    info['company_type'] = rg.type_string\n",
    "    info['logo_url'] = rl.img_string\n",
    "    info['location'] = rg.location_string\n",
    "    company_info.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9561974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3555"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(company_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0ad1ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "514dbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"job_title\", 'job_description', 'salary','work_type','url','skills','diploma','major','experience','source','company','city','state', 'location', 'category']\n",
    "with open('../csvfile_category/job_positions_full.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "    writer = csv.DictWriter(f, fieldnames = header)\n",
    "    writer.writeheader()\n",
    "    for job in job_info:\n",
    "        writer.writerow(job) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3d5a6de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_c = [\"company_name\",'city','state','location', 'size','website','industry','description','revenue','founded','company_type', 'logo_url']\n",
    "with open('../csvfile_category/company_full.csv', 'w') as f:  # You will need 'wb' mode in Python 2.x\n",
    "    writer = csv.DictWriter(f, fieldnames = header_c)\n",
    "    writer.writeheader()\n",
    "    for company in company_info:\n",
    "        writer.writerow(company) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539be284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
